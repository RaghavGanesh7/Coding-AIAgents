{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaghavGanesh7/Coding-AIAgents/blob/main/Langgraph_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZDOdT0Dj8eN",
        "outputId": "59ae729a-8f99-4d8b-cc61-f4c328ec49f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.6.7-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.76)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.4.28)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.6.7-py3-none-any.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed langgraph-0.6.7 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.9 ormsgpack-1.10.0\n"
          ]
        }
      ],
      "source": [
        "# Install the langgraph library\n",
        "!pip install langgraph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgicZlW6C0xU"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bpKME7IBVry-"
      },
      "outputs": [],
      "source": [
        "# Import necessary modules from typing and langgraph\n",
        "from typing import TypedDict,List\n",
        "from langgraph.graph import StateGraph, START, END"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kYj3Iyh7kDs0"
      },
      "outputs": [],
      "source": [
        "# Define a TypedDict for the agent's state\n",
        "# This defines the structure of the state object that will be passed between nodes in the graph\n",
        "class AgentState(TypedDict):\n",
        "    name:str\n",
        "    values: List[int]\n",
        "    result : str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zSwsdOY1mEtR"
      },
      "outputs": [],
      "source": [
        "# Define a function to process the values in the agent's state\n",
        "# This function takes the current state as input and updates it\n",
        "def process_values(state:AgentState):\n",
        "    # You can uncomment the print statement to see the state at this point\n",
        "    #print(state)\n",
        "    \"\"\"function to process multiple inputs\"\"\"\n",
        "    # Update the 'result' key in the state with a greeting and the sum of the values\n",
        "    state['result'] = \"Hi \" + state['name'] + \". Your sum is \" + str(sum(state['values']))\n",
        "    return state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zXSyRR01mtLt"
      },
      "outputs": [],
      "source": [
        "# Create a new StateGraph with the defined AgentState\n",
        "graph = StateGraph(AgentState)\n",
        "# Add a node named \"processor\" to the graph, using the process_values function\n",
        "graph.add_node(\"processor\", process_values)\n",
        "# Set the entry point of the graph to the \"processor\" node\n",
        "graph.set_entry_point(\"processor\")\n",
        "# Set the finish point of the graph to the \"processor\" node\n",
        "graph.set_finish_point(\"processor\")\n",
        "\n",
        "# Compile the graph into a runnable application\n",
        "app = graph.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "gI50fNXrnIQx",
        "outputId": "b73c2706-0ce4-45e4-831b-7f8da668eb2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hi Raghav. Your sum is 10'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Invoke the compiled graph with an initial state and print the 'result'\n",
        "# This demonstrates running the simple graph with a starting state\n",
        "app.invoke({\"name\":\"Raghav\",\"values\":[1,2,3,4]})['result']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "586tKamdfVAF"
      },
      "outputs": [],
      "source": [
        "# Define a TypedDict for a router's state\n",
        "# This state will hold information for routing based on an operator\n",
        "class RouterState(TypedDict):\n",
        "  operator : str\n",
        "  num1 : int\n",
        "  num2 : int\n",
        "  result : str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mE12OImkizQj"
      },
      "outputs": [],
      "source": [
        "# Define functions for different operations\n",
        "# These functions take the RouterState and update the result based on the operation\n",
        "\n",
        "def add_operation(state: RouterState):\n",
        "  # Print the state to see the input\n",
        "  print(state)\n",
        "  # Perform addition and update the result\n",
        "  state['result'] = str(state['num1'] + state['num2'])\n",
        "  return state\n",
        "\n",
        "def subtract_operation(state:RouterState):\n",
        "  # Perform subtraction and update the result\n",
        "  state['result'] = str(state['num1'] - state['num2'])\n",
        "  return state\n",
        "\n",
        "# Define a router function that determines the next node based on the 'operator'\n",
        "def myrouter(state:RouterState):\n",
        "  # Print the state to see the input\n",
        "  print(state)\n",
        "  # Return the name of the next node based on the operator\n",
        "  if state['operator'] == '+':\n",
        "    return \"add_operation\"\n",
        "  elif state['operator'] == '-':\n",
        "    return \"subtract_operation\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Pfs_icnTjYt_"
      },
      "outputs": [],
      "source": [
        "# Create a new StateGraph for the router\n",
        "graph = StateGraph(RouterState)\n",
        "# Add nodes for the add and subtract operations\n",
        "graph.add_node(\"add_node\", add_operation)\n",
        "graph.add_node(\"sub_node\", subtract_operation)\n",
        "# Add a router node that simply passes the state through (the routing logic is in add_conditional_edges)\n",
        "graph.add_node(\"router\", lambda state:state)\n",
        "\n",
        "# Define the graph's edges\n",
        "# Set the entry point to the router node\n",
        "graph.add_edge(START, \"router\");\n",
        "# Add conditional edges from the router based on the myrouter function\n",
        "# The output of myrouter (e.g., \"add_operation\") determines the next node\n",
        "graph.add_conditional_edges(\"router\",myrouter,{\n",
        "    \"add_operation\": \"add_node\",\n",
        "    \"subtract_operation\": \"sub_node\"\n",
        "})\n",
        "# Add edges from the operation nodes to the end point\n",
        "graph.add_edge(\"add_node\", END)\n",
        "graph.add_edge(\"sub_node\",END)\n",
        "\n",
        "# Compile the graph\n",
        "app = graph.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "2KbbANbQlcUL",
        "outputId": "e4a4bdff-f155-47b7-cfbe-f690985bf80a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'operator': '+', 'num1': 1, 'num2': 2}\n",
            "{'operator': '+', 'num1': 1, 'num2': 2}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Define an initial state for the router graph\n",
        "initState = RouterState(operator='+',num1=1,num2=2);\n",
        "# Invoke the compiled router graph with the initial state and print the result\n",
        "app.invoke(initState)['result']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "P05SrI5I4NEG"
      },
      "outputs": [],
      "source": [
        "# Define a TypedDict for the state of a guessing game agent\n",
        "class AgentState(TypedDict):\n",
        "  player_name:str\n",
        "  target: int\n",
        "  guesses: List[int]\n",
        "  attempts: int\n",
        "  lower: int\n",
        "  upper: int"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZczNXy0c77Gp"
      },
      "outputs": [],
      "source": [
        "# Define functions for the guessing game\n",
        "# Setup function to initialize the game state\n",
        "def setup(state:AgentState):\n",
        "  state['attempts'] = 0\n",
        "  state['lower'] = 0\n",
        "  state['upper'] = 100\n",
        "  state['guesses'] = []\n",
        "  return state\n",
        "\n",
        "# Guess function to make a guess based on the current range\n",
        "def guess(state:AgentState):\n",
        "  state['attempts'] += 1\n",
        "  state['guesses'].append((state['lower'] + state['upper']) // 2)\n",
        "  return state\n",
        "\n",
        "# Hint node function to provide a hint and update the range\n",
        "def hint_node(state:AgentState):\n",
        "  # Print the state to see the current game progress\n",
        "  print(state)\n",
        "  # Update the lower or upper bound based on the guess\n",
        "  if state['guesses'][-1] < state['target']:\n",
        "    state['lower'] = state['guesses'][-1]\n",
        "  elif state['guesses'][-1] > state['target']:\n",
        "    state['upper'] = state['guesses'][-1]\n",
        "  return state\n",
        "\n",
        "# Function to determine if the game should continue\n",
        "def should_continue(state:AgentState):\n",
        "  # Check if the last guess is the target or if the maximum attempts are reached\n",
        "  if state['guesses'][-1] == state['target']:\n",
        "    return \"continue\"\n",
        "  elif state['attempts'] > 10:\n",
        "    return \"continue\"\n",
        "  else:\n",
        "    return \"loop\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XEOPawd83TK",
        "outputId": "5704c5c5-4c09-4c2d-f526-0dc8a03ad026"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'player_name': 'Raghav', 'target': 60, 'guesses': [50], 'attempts': 1, 'lower': 0, 'upper': 100}\n",
            "{'player_name': 'Raghav', 'target': 60, 'guesses': [50, 75], 'attempts': 2, 'lower': 50, 'upper': 100}\n",
            "{'player_name': 'Raghav', 'target': 60, 'guesses': [50, 75, 62], 'attempts': 3, 'lower': 50, 'upper': 75}\n",
            "{'player_name': 'Raghav', 'target': 60, 'guesses': [50, 75, 62, 56], 'attempts': 4, 'lower': 50, 'upper': 62}\n",
            "{'player_name': 'Raghav', 'target': 60, 'guesses': [50, 75, 62, 56, 59], 'attempts': 5, 'lower': 56, 'upper': 62}\n",
            "{'player_name': 'Raghav', 'target': 60, 'guesses': [50, 75, 62, 56, 59, 60], 'attempts': 6, 'lower': 59, 'upper': 62}\n",
            "{'player_name': 'Raghav', 'target': 60, 'guesses': [50, 75, 62, 56, 59, 60], 'attempts': 6, 'lower': 59, 'upper': 62}\n"
          ]
        }
      ],
      "source": [
        "# Create a new StateGraph for the guessing game\n",
        "graph = StateGraph(AgentState)\n",
        "# Add nodes for setup, guessing (loop), hinting, and checking to continue\n",
        "graph.add_node(\"setup\",setup)\n",
        "graph.add_node(\"loop\",guess)\n",
        "graph.add_node(\"hint\",hint_node)\n",
        "# The should_continue node here is just a placeholder as the logic is in add_conditional_edges\n",
        "graph.add_node(\"should_continue\",lambda x:x)\n",
        "\n",
        "# Define the graph's edges\n",
        "# Set the entry point to the setup node\n",
        "graph.add_edge(START,\"setup\")\n",
        "# Connect setup to the guessing loop\n",
        "graph.add_edge(\"setup\",\"loop\")\n",
        "# Connect the guessing loop to the hint node\n",
        "graph.add_edge(\"loop\",\"hint\")\n",
        "# Add conditional edges from the hint node based on the should_continue function\n",
        "# The return value of should_continue determines if the game loops or ends\n",
        "graph.add_conditional_edges(\"hint\",should_continue,{\n",
        "    \"continue\": END, # If should_continue returns \"continue\", the graph ends\n",
        "    \"loop\": \"loop\" # If should_continue returns \"loop\", the graph goes back to the guess node\n",
        "})\n",
        "# Add an edge from hint to END (This edge seems redundant given the conditional edges, might be a leftover)\n",
        "graph.add_edge(\"hint\",END)\n",
        "\n",
        "# Compile the graph\n",
        "app = graph.compile()\n",
        "# Define the initial state for the guessing game\n",
        "init_state = AgentState(target=60,player_name=\"Raghav\")\n",
        "# Invoke the compiled graph with the initial state and print the final state\n",
        "print(app.invoke(init_state))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bVEbQ7d5C3Da",
        "outputId": "a8ca92c5-51d4-4fae-91d2-be4692848991"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (0.6.7)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.76)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.1.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.6.4)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.2.9)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.4.28)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
            "Collecting langchain_google_genai\n",
            "  Downloading langchain_google_genai-2.1.12-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: langchain-core>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (0.3.76)\n",
            "Collecting google-ai-generativelanguage<1,>=0.7 (from langchain_google_genai)\n",
            "  Downloading google_ai_generativelanguage-0.7.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (2.11.9)\n",
            "Collecting filetype<2,>=1.2 (from langchain_google_genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (5.29.5)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain_google_genai) (0.4.28)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain_google_genai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain_google_genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain_google_genai) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain_google_genai) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain_google_genai) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain_google_genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain_google_genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain_google_genai) (0.4.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (2.32.4)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (1.75.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.3.75->langchain_google_genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (0.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (1.3.1)\n",
            "Downloading langchain_google_genai-2.1.12-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.7.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, google-ai-generativelanguage, langchain_google_genai\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filetype-1.2.0 google-ai-generativelanguage-0.7.0 langchain_google_genai-2.1.12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "d0474914b52f46cd84ba21930f11cde5"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Install necessary libraries: langgraph and langchain_google_genai\n",
        "# langgraph is for building agent graphs\n",
        "# langchain_google_genai provides integration with Google's Generative AI models\n",
        "!pip install langgraph\n",
        "\n",
        "!pip install langchain_google_genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lpGaITb5PyYc"
      },
      "outputs": [],
      "source": [
        "# Import required modules\n",
        "# ChatGoogleGenerativeAI for using Google's chat models\n",
        "# TypedDict, List, Union for type hinting\n",
        "# StateGraph, START, END for building the graph\n",
        "# HumanMessage, AIMessage for representing messages in a conversation\n",
        "# userdata for accessing Colab secrets (like API keys)\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from typing import TypedDict,List,Union\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "qXYEAvg7DvLS",
        "outputId": "fd8b89f2-4192-4e84-d645-033ebba463e9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3486238152.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mconversation_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter :\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"exit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "# Define the AgentState for this graph, which contains a list of messages\n",
        "class AgentState(TypedDict):\n",
        "  messages: List[Union[HumanMessage,AIMessage]]\n",
        "\n",
        "# Initialize the ChatGoogleGenerativeAI model\n",
        "# Replace 'YOUR_API_KEY' with your actual API key or use userdata.get to access it from Colab secrets\n",
        "llm  = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "\n",
        "# Define a function to process the state using the LLM\n",
        "def ex_process(state:AgentState):\n",
        "  # Invoke the LLM with the current messages in the state\n",
        "  response = llm.invoke(state['messages'])\n",
        "  # Append the AI's response to the messages in the state\n",
        "  state['messages'].append(AIMessage(content=response.content))\n",
        "  # Print the AI's response\n",
        "  print(response.content)\n",
        "  return state\n",
        "\n",
        "# Create a new StateGraph\n",
        "graph = StateGraph(AgentState)\n",
        "# Add a node named \"ex_process\" using the ex_process function\n",
        "graph.add_node(\"ex_process\", ex_process)\n",
        "# Set the entry point to \"ex_process\"\n",
        "graph.add_edge(START,\"ex_process\")\n",
        "# Set the finish point to \"ex_process\"\n",
        "graph.add_edge(\"ex_process\",END)\n",
        "\n",
        "# Compile the graph\n",
        "agent = graph.compile()\n",
        "\n",
        "# Initialize the conversation history\n",
        "conversation_history = []\n",
        "\n",
        "# Start an interactive loop for conversation\n",
        "user_input = input(\"Enter :\")\n",
        "\n",
        "while(user_input != \"exit\"):\n",
        "  # Append the user's input as a HumanMessage to the history\n",
        "  conversation_history.append(HumanMessage(content=user_input))\n",
        "  # Invoke the agent with the current conversation history\n",
        "  state = agent.invoke({\"messages\":conversation_history})\n",
        "  # Update the conversation history with the new state (including the AI's response)\n",
        "  conversation_history = state['messages']\n",
        "  # Get the next user input\n",
        "  user_input = input(\"Enter :\")\n",
        "  # The commented line below is an alternative way to invoke the agent, but the loop above is used here\n",
        "  #agent.invoke({\"message\":[HumanMessage(content=\"Hi\")]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFObYnkEZx7G",
        "outputId": "d85f2f69-10d8-4647-884f-d6213d95d9d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.76)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.28)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.9)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "# Install the langchain library\n",
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "880hzKrBXhYe"
      },
      "outputs": [],
      "source": [
        "# Import necessary modules for building an agent with tools\n",
        "# ChatGoogleGenerativeAI for using Google's chat models\n",
        "# Annotated, Sequence, TypedDict, List, Union for type hinting\n",
        "# StateGraph, START, END for building the graph\n",
        "# tool for defining tools\n",
        "# add_messages for handling message history in the state\n",
        "# ToolNode for creating a node that executes tools\n",
        "# HumanMessage, AIMessage, BaseMessage, ToolMessage, SystemMessage for different message types\n",
        "# userdata for accessing Colab secrets\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from typing import Annotated,Sequence,TypedDict,List,Union\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from langchain_core.messages import BaseMessage\n",
        "from langchain_core.messages import ToolMessage\n",
        "from langchain_core.messages import SystemMessage\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTwu2ErAaKEl",
        "outputId": "fdac1e49-7ca4-4d0e-c539-ef0f6c896a38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Add 5+5. And then multiply the result with 5. Also who created you?\n",
            "\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  add (9fc37050-c5cc-4b06-b086-f8865ad96ad2)\n",
            " Call ID: 9fc37050-c5cc-4b06-b086-f8865ad96ad2\n",
            "  Args:\n",
            "    a: 5\n",
            "    b: 5\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: add\n",
            "\n",
            "10\n",
            "\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  multiply (d1b7b1bf-4da2-4dcf-9996-41fb5d54388b)\n",
            " Call ID: d1b7b1bf-4da2-4dcf-9996-41fb5d54388b\n",
            "  Args:\n",
            "    a: 10\n",
            "    b: 5\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: multiply\n",
            "\n",
            "50\n",
            "I am a large language model, trained by Google.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "I am a large language model, trained by Google.\n",
            "Tool Calls:\n",
            "  add (7e1168fe-60b9-49db-bda5-3c2c6e5ccb95)\n",
            " Call ID: 7e1168fe-60b9-49db-bda5-3c2c6e5ccb95\n",
            "  Args:\n",
            "    a: 5\n",
            "    b: 5\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: add\n",
            "\n",
            "10\n",
            "I am a large language model, trained by Google. The final answer is 50.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "I am a large language model, trained by Google. The final answer is 50.\n"
          ]
        }
      ],
      "source": [
        "# Define the AgentState for this graph, which includes message history\n",
        "class AgentState(TypedDict):\n",
        "  messages: Annotated[Sequence[BaseMessage], add_messages]\n",
        "\n",
        "# Define tools that the agent can use\n",
        "@tool\n",
        "def add(a:int, b:int):\n",
        "  \"\"\"This is a addition function to add two numbers\"\"\"\n",
        "  return a+b\n",
        "\n",
        "def multiply(a:int, b:int):\n",
        "  \"\"\"This is a multiplication function to multiply two numbers\"\"\"\n",
        "  return a*b\n",
        "\n",
        "# List of available tools\n",
        "tools = [add,multiply]\n",
        "# Initialize the LLM and bind the tools to it\n",
        "llm  = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\", api_key=userdata.get('GOOGLE_API_KEY')).bind_tools(tools)\n",
        "\n",
        "# Define a node that calls the LLM\n",
        "def mode_call(state:AgentState):\n",
        "  # Define a system prompt for the AI's role\n",
        "  system_prompt = SystemMessage(content=\"You a AI Agent. Answer to best of your ability\")\n",
        "  # Invoke the LLM with the system prompt and the current messages\n",
        "  response = llm.invoke([system_prompt] + state[\"messages\"])\n",
        "  # Print the AI's response\n",
        "  print(response.content)\n",
        "  # Return the state with the AI's response added\n",
        "  return {'messages': [response]}\n",
        "\n",
        "# Define a function to determine if the graph should continue based on tool calls\n",
        "def should_continue(state:AgentState):\n",
        "  messages = state['messages']\n",
        "  last_message = messages[-1]\n",
        "  # If the last message has no tool calls, end the graph\n",
        "  if not last_message.tool_calls:\n",
        "    return \"end\"\n",
        "  # If the last message has tool calls, continue to the tools node\n",
        "  else:\n",
        "    return \"continue\"\n",
        "\n",
        "# Create a new StateGraph\n",
        "graph = StateGraph(AgentState)\n",
        "# Add the LLM call node\n",
        "graph.add_node(\"mode_call\", mode_call)\n",
        "# Add the tool node, which will execute the tool calls\n",
        "tool_node = ToolNode(tools=tools)\n",
        "graph.add_node(\"tools\",tool_node)\n",
        "# Add conditional edges from the mode_call node based on the should_continue function\n",
        "# If should_continue returns \"continue\", go to the \"tools\" node\n",
        "# If should_continue returns \"end\", go to the END point\n",
        "graph.add_conditional_edges(\"mode_call\",should_continue,{\n",
        "    \"continue\": \"tools\",\n",
        "    \"end\": END\n",
        "})\n",
        "# Set the entry point to the mode_call node\n",
        "graph.set_entry_point(\"mode_call\")\n",
        "# Add an edge from the tools node back to the mode_call node to get the LLM's response to the tool results\n",
        "graph.add_edge(\"tools\",\"mode_call\")\n",
        "\n",
        "# Compile the graph\n",
        "app = graph.compile()\n",
        "\n",
        "# Define a helper function to print the streamed output\n",
        "def print_stream(stream):\n",
        "  for s in stream:\n",
        "    message = s['messages'][-1]\n",
        "    if isinstance(message, tuple):\n",
        "      print(message)\n",
        "    else:\n",
        "      message.pretty_print()\n",
        "\n",
        "# Define the initial input for the agent\n",
        "inputs = {\"messages\":[(\"user\",\"Add 5+5. And then multiply the result with 5. Also who created you?\")]}\n",
        "\n",
        "# Run the agent with streaming and print the output\n",
        "print_stream(app.stream(inputs,stream_mode=\"values\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a global variable to store the document content\n",
        "document_content = \"\"\n",
        "\n",
        "# Define the AgentState for this document agent, including message history\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
        "\n",
        "# Define tools for the document agent\n",
        "\n",
        "@tool\n",
        "def update(content: str) -> str:\n",
        "    \"\"\"Updates the document with the provided content.\"\"\"\n",
        "    global document_content\n",
        "    document_content = content\n",
        "    return f\"Document has been updated successfully! The current content is:\\n{document_content}\"\n",
        "\n",
        "@tool\n",
        "def save(filename: str) -> str:\n",
        "    \"\"\"Save the current document to a text file and finish the process.\n",
        "\n",
        "    Args:\n",
        "        filename: Name for the text file.\n",
        "    \"\"\"\n",
        "\n",
        "    global document_content\n",
        "\n",
        "    # Ensure the filename ends with .txt\n",
        "    if not filename.endswith('.txt'):\n",
        "        filename = f\"{filename}.txt\"\n",
        "\n",
        "    try:\n",
        "        # Write the document content to the specified file\n",
        "        with open(filename, 'w') as file:\n",
        "            file.write(document_content)\n",
        "        print(f\"\\n💾 Document has been saved to: {filename}\")\n",
        "        return f\"Document has been saved successfully to '{filename}'.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error saving document: {str(e)}\"\n",
        "\n",
        "# List of available tools for the agent\n",
        "tools = [update, save]\n",
        "\n",
        "# Initialize the ChatGoogleGenerativeAI model and bind the tools\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\", api_key=userdata.get('GOOGLE_API_KEY')).bind_tools(tools)\n",
        "\n",
        "# Define the main agent function\n",
        "def our_agent(state: AgentState) -> AgentState:\n",
        "    # Define the system prompt for the agent\n",
        "    system_prompt = SystemMessage(content=f\"\"\"\n",
        "    You are Drafter, a helpful writing assistant. You are going to help the user update and modify documents.\n",
        "\n",
        "    - If the user wants to update or modify content, use the 'update' tool with the complete updated content.\n",
        "    - If the user wants to save and finish, you need to use the 'save' tool.\n",
        "    - Make sure to always show the current document state after modifications.\n",
        "\n",
        "    The current document content is:{document_content}\n",
        "    \"\"\")\n",
        "\n",
        "    # Handle the initial state where there are no messages\n",
        "    if not state[\"messages\"]:\n",
        "        user_input = \"I'm ready to help you update a document. What would you like to create?\"\n",
        "        user_message = HumanMessage(content=user_input)\n",
        "    else:\n",
        "        # Get user input during the conversation\n",
        "        user_input = input(\"\\nWhat would you like to do with the document? \")\n",
        "        print(f\"\\n👤 USER: {user_input}\")\n",
        "        user_message = HumanMessage(content=user_input)\n",
        "\n",
        "    # Combine system prompt, existing messages, and new user message\n",
        "    all_messages = [system_prompt] + list(state[\"messages\"]) + [user_message]\n",
        "\n",
        "    # Invoke the model with all messages\n",
        "    response = model.invoke(all_messages)\n",
        "\n",
        "    # Print the AI's response and indicate if tools are being used\n",
        "    print(f\"\\n🤖 AI: {response.content}\")\n",
        "    if hasattr(response, \"tool_calls\") and response.tool_calls:\n",
        "        print(f\"🔧 USING TOOLS: {[tc['name'] for tc in response.tool_calls]}\")\n",
        "\n",
        "    # Return the updated state with the user message and AI response\n",
        "    return {\"messages\": list(state[\"messages\"]) + [user_message, response]}\n",
        "\n",
        "# Define a function to determine if the conversation should continue\n",
        "def should_continue(state: AgentState) -> str:\n",
        "    \"\"\"Determine if we should continue or end the conversation.\"\"\"\n",
        "\n",
        "    messages = state[\"messages\"]\n",
        "\n",
        "    # Continue if there are no messages (initial state)\n",
        "    if not messages:\n",
        "        return \"continue\"\n",
        "\n",
        "    # This looks for the most recent tool message....\n",
        "    for message in reversed(messages):\n",
        "        # ... and checks if this is a ToolMessage resulting from a successful save\n",
        "        if (isinstance(message, ToolMessage) and\n",
        "            \"saved\" in message.content.lower() and\n",
        "            \"document\" in message.content.lower()):\n",
        "            # If a save tool message is found, end the graph\n",
        "            return \"end\" # goes to the end edge which leads to the endpoint\n",
        "\n",
        "    # Otherwise, continue the conversation\n",
        "    return \"continue\"\n",
        "\n",
        "# Define a helper function to print messages in a readable format\n",
        "def print_messages(messages):\n",
        "    \"\"\"Function I made to print the messages in a more readable format\"\"\"\n",
        "    if not messages:\n",
        "        return\n",
        "\n",
        "    # Print the last 3 messages\n",
        "    for message in messages[-3:]:\n",
        "        if isinstance(message, ToolMessage):\n",
        "            print(f\"\\n🛠️ TOOL RESULT: {message.content}\")\n",
        "\n",
        "\n",
        "# Create a new StateGraph\n",
        "graph = StateGraph(AgentState)\n",
        "\n",
        "# Add the agent and tools nodes\n",
        "graph.add_node(\"agent\", our_agent)\n",
        "graph.add_node(\"tools\", ToolNode(tools))\n",
        "\n",
        "# Set the entry point to the agent node\n",
        "graph.set_entry_point(\"agent\")\n",
        "\n",
        "# Add an edge from the agent to the tools node\n",
        "graph.add_edge(\"agent\", \"tools\")\n",
        "\n",
        "# Add conditional edges from the tools node based on the should_continue function\n",
        "# If should_continue returns \"continue\", go back to the \"agent\" node\n",
        "# If should_continue returns \"end\", go to the END point\n",
        "graph.add_conditional_edges(\n",
        "    \"tools\",\n",
        "    should_continue,\n",
        "    {\n",
        "        \"continue\": \"agent\",\n",
        "        \"end\": END,\n",
        "    },\n",
        ")\n",
        "\n",
        "# Compile the graph\n",
        "app = graph.compile()\n",
        "\n",
        "# Define the main function to run the document agent\n",
        "def run_document_agent():\n",
        "    print(\"\\n ===== DRAFTER =====\")\n",
        "\n",
        "    # Initialize the state\n",
        "    state = {\"messages\": []}\n",
        "\n",
        "    # Stream the output of the graph and print messages\n",
        "    for step in app.stream(state, stream_mode=\"values\"):\n",
        "        if \"messages\" in step:\n",
        "            print_messages(step[\"messages\"])\n",
        "\n",
        "    print(\"\\n ===== DRAFTER FINISHED =====\")\n",
        "\n",
        "# Run the document agent when the script is executed\n",
        "if __name__ == \"__main__\":\n",
        "    run_document_agent()"
      ],
      "metadata": {
        "id": "_yTha7bUKQFz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98700332-5b01-4126-9c9d-900d934a93f2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ===== DRAFTER =====\n",
            "\n",
            "🤖 AI: I will start with a simple document.\n",
            "\n",
            "This is a document about my cat.\n",
            "\n",
            "First, please add a title to this document.\n",
            "\n",
            "What would you like to do with the document? My cats name is bangu\n",
            "\n",
            "👤 USER: My cats name is bangu\n",
            "\n",
            "🤖 AI: \n",
            "🔧 USING TOOLS: ['update']\n",
            "\n",
            "🛠️ TOOL RESULT: Document has been updated successfully! The current content is:\n",
            "My Cat Bangu\n",
            "\n",
            "This is a document about my cat.\n",
            "\n",
            "What would you like to do with the document? save the document\n",
            "\n",
            "👤 USER: save the document\n",
            "\n",
            "🤖 AI: What file name should I use?\n",
            "\n",
            "🛠️ TOOL RESULT: Document has been updated successfully! The current content is:\n",
            "My Cat Bangu\n",
            "\n",
            "This is a document about my cat.\n",
            "\n",
            "🛠️ TOOL RESULT: Document has been updated successfully! The current content is:\n",
            "My Cat Bangu\n",
            "\n",
            "This is a document about my cat.\n",
            "\n",
            "What would you like to do with the document? cat.txt\n",
            "\n",
            "👤 USER: cat.txt\n",
            "\n",
            "🤖 AI: \n",
            "🔧 USING TOOLS: ['save']\n",
            "\n",
            "💾 Document has been saved to: cat.txt\n",
            "\n",
            "🛠️ TOOL RESULT: Document has been saved successfully to 'cat.txt'.\n",
            "\n",
            " ===== DRAFTER FINISHED =====\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries for RAG (Retrieval Augmented Generation)\n",
        "# langchain_community for various components like document loaders\n",
        "# pypdf for loading PDF documents\n",
        "# langchain_chroma for using Chroma as a vector store\n",
        "!pip install langchain_community pypdf langchain_chroma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "10zS9lPpeOdY",
        "outputId": "a64a4473-b38e-4346-b93b-90b29e1be726"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.12/dist-packages (0.3.30)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.1.1)\n",
            "Collecting langchain_chroma\n",
            "  Downloading langchain_chroma-0.2.6-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.76)\n",
            "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.43)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.10.1)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.28)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Collecting chromadb>=1.0.20 (from langchain_chroma)\n",
            "  Downloading chromadb-1.1.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (1.3.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (2.11.9)\n",
            "Collecting pybase64>=1.4.1 (from chromadb>=1.0.20->langchain_chroma)\n",
            "  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.20->langchain_chroma) (0.35.0)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb>=1.0.20->langchain_chroma)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (4.15.0)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb>=1.0.20->langchain_chroma)\n",
            "  Downloading onnxruntime-1.23.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (1.37.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb>=1.0.20->langchain_chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (1.37.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (0.22.0)\n",
            "Collecting pypika>=0.48.9 (from chromadb>=1.0.20->langchain_chroma)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (1.75.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb>=1.0.20->langchain_chroma)\n",
            "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (0.17.4)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb>=1.0.20->langchain_chroma)\n",
            "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb>=1.0.20->langchain_chroma)\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (3.11.3)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (4.25.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (0.3.11)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (25.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.2.4)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb>=1.0.20->langchain_chroma) (1.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb>=1.0.20->langchain_chroma) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb>=1.0.20->langchain_chroma) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=1.0.20->langchain_chroma) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.20->langchain_chroma) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.20->langchain_chroma) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.20->langchain_chroma) (0.27.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain_chroma) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain_chroma) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain_chroma) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain_chroma) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain_chroma) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain_chroma) (3.3.1)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain_chroma)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb>=1.0.20->langchain_chroma)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.20->langchain_chroma) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.20->langchain_chroma) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.20->langchain_chroma) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb>=1.0.20->langchain_chroma) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.20->langchain_chroma) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.37.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.20->langchain_chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.37.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.20->langchain_chroma)\n",
            "  Downloading opentelemetry_proto-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb>=1.0.20->langchain_chroma) (0.58b0)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.20->langchain_chroma)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.20->langchain_chroma) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb>=1.0.20->langchain_chroma) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb>=1.0.20->langchain_chroma) (2.33.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb>=1.0.20->langchain_chroma) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb>=1.0.20->langchain_chroma) (2.19.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb>=1.0.20->langchain_chroma) (0.35.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb>=1.0.20->langchain_chroma) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb>=1.0.20->langchain_chroma) (1.5.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.20->langchain_chroma)\n",
            "  Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.20->langchain_chroma)\n",
            "  Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.20->langchain_chroma)\n",
            "  Downloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.20->langchain_chroma) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.20->langchain_chroma) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.20->langchain_chroma) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.20->langchain_chroma) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.20->langchain_chroma) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.20->langchain_chroma) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.20->langchain_chroma) (1.1.10)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb>=1.0.20->langchain_chroma) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=1.0.20->langchain_chroma) (0.1.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb>=1.0.20->langchain_chroma) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb>=1.0.20->langchain_chroma)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=1.0.20->langchain_chroma) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.20->langchain_chroma) (0.6.1)\n",
            "Downloading langchain_chroma-0.2.6-py3-none-any.whl (12 kB)\n",
            "Downloading chromadb-1.1.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.37.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (510 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=444b15e6c17d2db39057afcd2aee942f037dccb3cb21ef2ccdf4ddbaeaa2bee6\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, pybase64, opentelemetry-proto, mmh3, humanfriendly, httptools, bcrypt, backoff, watchfiles, posthog, opentelemetry-exporter-otlp-proto-common, coloredlogs, onnxruntime, kubernetes, opentelemetry-exporter-otlp-proto-grpc, chromadb, langchain_chroma\n",
            "Successfully installed backoff-2.2.1 bcrypt-5.0.0 chromadb-1.1.0 coloredlogs-15.0.1 durationpy-0.10 httptools-0.6.4 humanfriendly-10.0 kubernetes-33.1.0 langchain_chroma-0.2.6 mmh3-5.2.0 onnxruntime-1.23.0 opentelemetry-exporter-otlp-proto-common-1.37.0 opentelemetry-exporter-otlp-proto-grpc-1.37.0 opentelemetry-proto-1.37.0 posthog-5.4.0 pybase64-1.4.2 pypika-0.48.9 uvloop-0.21.0 watchfiles-1.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "opentelemetry"
                ]
              },
              "id": "fa8f0477963f459688a558ca0bdf0b12"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "# ChatGoogleGenerativeAI for the LLM\n",
        "# TypedDict, List, Union for type hinting\n",
        "# StateGraph, START, END for building the graph\n",
        "# tool for defining tools\n",
        "# add_messages for handling message history\n",
        "# ToolNode for executing tools\n",
        "# HumanMessage, AIMessage, BaseMessage, ToolMessage, SystemMessage for message types\n",
        "# userdata for accessing Colab secrets\n",
        "# GoogleGenerativeAIEmbeddings for creating embeddings\n",
        "# PyPDFLoader for loading PDF documents\n",
        "# RecursiveCharacterTextSplitter for splitting text\n",
        "# Chroma for the vector store\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from typing import Annotated,Sequence,TypedDict,List,Union\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage, ToolMessage, SystemMessage\n",
        "from google.colab import userdata\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_chroma import Chroma\n",
        "\n",
        "\n",
        "# Initialize the LLM\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\",\n",
        " api_key=userdata.get('GOOGLE_API_KEY'),temperature=0)\n",
        "\n",
        "# Initialize the embeddings model\n",
        "embeddings = GoogleGenerativeAIEmbeddings(\n",
        "    model=\"models/gemini-embedding-001\",\n",
        "    google_api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "\n",
        "# Specify the document name\n",
        "document_name = \"Stock_Market_Performance_2024.pdf\"\n",
        "\n",
        "# Check if the document exists\n",
        "if not os.path.exists(document_name):\n",
        "  raise FileNotFoundError(f\"PDF file not found\")\n",
        "\n",
        "# Initialize the PDF loader\n",
        "pdf_loader = PyPDFLoader(document_name)\n",
        "\n",
        "# Load the pages from the PDF document\n",
        "try:\n",
        "  pages = pdf_loader.load()\n",
        "except Exception as e:\n",
        "  raise Exception(f\"Error loading PDF: {e}\")\n",
        "\n",
        "# Initialize the text splitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "\n",
        "# Split the loaded pages into chunks\n",
        "pages_split = text_splitter.split_documents(pages)\n",
        "\n",
        "# Specify the directory and collection name for the Chroma vector store\n",
        "persist_directory = \"/content/\"\n",
        "collection_name = \"stockmarket\"\n",
        "\n",
        "# Create the persist directory if it doesn't exist\n",
        "if not os.path.exists(persist_directory):\n",
        "  os.mkdir(persist_directory)\n",
        "\n",
        "# Create or load the Chroma vector store from the document chunks\n",
        "try:\n",
        "  vector_store = Chroma.from_documents(\n",
        "    documents=pages_split,\n",
        "    embedding=embeddings,\n",
        "    persist_directory=persist_directory,\n",
        "    collection_name=collection_name\n",
        "  )\n",
        "  print(f\"Created ChromaDB vector store\")\n",
        "except Exception as e:\n",
        "  raise Exception\n",
        "\n",
        "# Create a retriever from the vector store\n",
        "retriever = vector_store.as_retriever(search_type=\"similarity\",search_kwargs={\"k\":5})\n",
        "\n",
        "# Define a tool for retrieving information from the document\n",
        "@tool\n",
        "def retriever_tool(query:str)->str:\n",
        "  \"\"\"\n",
        "  This tool searches and returns the information from the Stock Information document.\n",
        "  \"\"\"\n",
        "  # Invoke the retriever with the user's query\n",
        "  docs = retriever.invoke(query)\n",
        "\n",
        "  # Check if any relevant documents were found\n",
        "  if not docs:\n",
        "    return \"I found no relevant information in the Stock Market Performance 2024 document.\"\n",
        "  # Format the retrieved document content\n",
        "  results = []\n",
        "  for i,doc in enumerate(docs):\n",
        "    results.append(f\"Document {i+1}:\\n{doc.page_content}\")\n",
        "  return \"\\n\".join(results)\n",
        "\n",
        "# List of available tools for the agent\n",
        "tools = [retriever_tool]\n",
        "\n",
        "# Bind the tools to the LLM\n",
        "llm = llm.bind_tools(tools)\n",
        "\n",
        "# Define the AgentState for this RAG agent\n",
        "class AgentState(TypedDict):\n",
        "  messages: Annotated[Sequence[BaseMessage], add_messages]\n",
        "\n",
        "# Define a function to determine if the graph should continue based on tool calls\n",
        "def should_continue(state:AgentState):\n",
        "  \"\"\"\n",
        "  Checks if the last message contains tool calls\n",
        "  \"\"\"\n",
        "  result = state[\"messages\"][-1]\n",
        "  # Return \"continue\" if there are tool calls, otherwise return \"end\"\n",
        "  if hasattr(result,'tool_calls') and len(result.tool_calls)>0:\n",
        "    return \"continue\"\n",
        "  else:\n",
        "    return \"end\"\n",
        "\n",
        "# Define the system prompt for the RAG agent\n",
        "system_prompt = \"\"\"\n",
        "You are an intelligent AI assistant who answers questions about Stock Market Performance in 2024 based on the PDF document loaded into your knowledge base.\n",
        "Use the retriever tool available to answer questions about the stock market performance data. You can make multiple calls if needed.\n",
        "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
        "Please always cite the specific parts of the documents you use in your answers.\n",
        "\"\"\"\n",
        "\n",
        "# Create a dictionary of tools for easy access by name\n",
        "tools_dict = {our_tool.name: our_tool for our_tool in tools}\n",
        "\n",
        "# Define a node that calls the LLM\n",
        "def call_llm(state:AgentState):\n",
        "  # Get the current messages and add the system prompt\n",
        "  messages = list(state[\"messages\"])\n",
        "  messages = [SystemMessage(content=system_prompt)] + messages\n",
        "  # Invoke the LLM\n",
        "  messages = llm.invoke(messages)\n",
        "  # Return the state with the LLM's response\n",
        "  return {'messages':messages}\n",
        "\n",
        "# Define a node that executes tool calls\n",
        "def take_action(state:AgentState) -> AgentState:\n",
        "  \"\"\"Execute tool calls from LLM's response\"\"\"\n",
        "  # Get the tool calls from the last message\n",
        "  tool_calls = state[\"messages\"][-1].tool_calls\n",
        "  tool_messages = []\n",
        "  # Iterate through each tool call\n",
        "  for t in tool_calls:\n",
        "    print(f\"Calling tools:{t['name']} with query {t['args'].get('query')}\")\n",
        "    # Check if the tool exists\n",
        "    if not t['name'] in tools_dict:\n",
        "      print(f\"Tool {t['name']} not found\")\n",
        "      tool_messages.append(ToolMessage(tool_call_id=t['id'],content=\"Incorrect tool name received\",name=t['name']))\n",
        "    else:\n",
        "      # Invoke the tool and get the result\n",
        "      result = tools_dict[t['name']].invoke(t['args'].get('query',''))\n",
        "      print(\"Result length\",str(len(result)))\n",
        "      # Append the tool result as a ToolMessage\n",
        "      tool_messages.append(ToolMessage(tool_call_id=t['id'],content=str(result),name=t['name']))\n",
        "\n",
        "  print(\"Tool execution completed\")\n",
        "  # Return the state with the tool messages\n",
        "  return {\"messages\":tool_messages }\n",
        "\n",
        "# Create a new StateGraph\n",
        "graph = StateGraph(AgentState)\n",
        "# Add the LLM call node and the retriever agent (tool execution) node\n",
        "graph.add_node(\"call_llm\",call_llm)\n",
        "graph.add_node(\"retriever_agent\",take_action)\n",
        "# Add conditional edges from the call_llm node based on should_continue\n",
        "# If should_continue returns \"continue\", go to the retriever_agent\n",
        "# If should_continue returns \"end\", go to the END point\n",
        "graph.add_conditional_edges(\"call_llm\",\n",
        "should_continue\n",
        ",{\n",
        "    \"continue\": \"retriever_agent\",\n",
        "    \"end\": END\n",
        "})\n",
        "\n",
        "# Add an edge from the retriever_agent back to call_llm to process the tool results\n",
        "graph.add_edge(\"retriever_agent\",\"call_llm\")\n",
        "# Set the entry point to the call_llm node\n",
        "graph.set_entry_point(\"call_llm\")\n",
        "\n",
        "# Compile the graph\n",
        "rag_agent = graph.compile()\n",
        "\n",
        "# Define the main function to run the RAG agent\n",
        "def running_agent():\n",
        "    print(\"\\n=== RAG AGENT===\")\n",
        "\n",
        "    # Start an interactive loop for questions\n",
        "    while True:\n",
        "        user_input = input(\"\\nWhat is your question: \")\n",
        "        # Exit the loop if the user types 'exit' or 'quit'\n",
        "        if user_input.lower() in ['exit', 'quit']:\n",
        "            break\n",
        "\n",
        "        # Create a HumanMessage from the user input\n",
        "        messages = [HumanMessage(content=user_input)] # converts back to a HumanMessage type\n",
        "\n",
        "        # Invoke the RAG agent with the user's message\n",
        "        result = rag_agent.invoke({\"messages\": messages})\n",
        "\n",
        "        # Print the final answer from the agent\n",
        "        print(\"\\n=== ANSWER ===\")\n",
        "        print(result['messages'][-1].content)\n",
        "\n",
        "# Run the RAG agent when the script is executed\n",
        "running_agent()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "597c42ad-6a45-4e41-fba0-1a641173e425",
        "id": "oskXka5Uexcv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "Error loading PDF: `pypdf` package not found, please install it with `pip install pypdf`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_community/document_loaders/parsers/pdf.py\u001b[0m in \u001b[0;36mlazy_parse\u001b[0;34m(self, blob)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0;32mimport\u001b[0m \u001b[0mpypdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pypdf'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1505097063.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0mpages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdf_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/document_loaders/base.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \"\"\"\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_community/document_loaders/pdf.py\u001b[0m in \u001b[0;36mlazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mblob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_community/document_loaders/parsers/pdf.py\u001b[0m in \u001b[0;36mlazy_parse\u001b[0;34m(self, blob)\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m             raise ImportError(\n\u001b[0m\u001b[1;32m    362\u001b[0m                 \u001b[0;34m\"`pypdf` package not found, please install it with `pip install pypdf`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: `pypdf` package not found, please install it with `pip install pypdf`",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1505097063.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mpages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdf_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error loading PDF: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: Error loading PDF: `pypdf` package not found, please install it with `pip install pypdf`"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from typing import Annotated,Sequence,TypedDict,List,Union\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage, ToolMessage, SystemMessage\n",
        "from google.colab import userdata\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_chroma import Chroma\n",
        "import os\n"
      ],
      "metadata": {
        "id": "OHGkA6lGcnPj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from genericpath import exists\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\",\n",
        " api_key=userdata.get('GOOGLE_API_KEY'),temperature=0)\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(\n",
        "    model=\"models/gemini-embedding-001\",\n",
        "    google_api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "\n",
        "document_name = \"Stock_Market_Performance_2024.pdf\"\n",
        "\n",
        "if not os.path.exists(document_name):\n",
        "  raise FileNotFoundError(f\"PDF file not found\")\n",
        "\n",
        "\n",
        "pdf_loader = PyPDFLoader(document_name)\n",
        "\n",
        "try:\n",
        "  pages = pdf_loader.load()\n",
        "except Exception as e:\n",
        "  raise Exception(f\"Error loading PDF: {e}\")\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "\n",
        "pages_split = text_splitter.split_documents(pages)\n",
        "\n",
        "\n",
        "persist_directory = \"/content/\"\n",
        "collection_name = \"stockmarket\"\n",
        "\n",
        "if not os.path.exists(persist_directory):\n",
        "  os.mkdir(persist_directory)\n",
        "\n",
        "try:\n",
        "  vector_store = Chroma.from_documents(\n",
        "    documents=pages_split,\n",
        "    embedding=embeddings,\n",
        "    persist_directory=persist_directory,\n",
        "    collection_name=collection_name\n",
        "  )\n",
        "  print(f\"Created ChromaDB vector store\")\n",
        "except Exception as e:\n",
        "  raise Exception\n",
        "\n",
        "retriever = vector_store.as_retriever(search_type=\"similarity\",search_kwargs={\"k\":5})\n",
        "\n",
        "@tool\n",
        "def retriever_tool(query:str)->str:\n",
        "  \"\"\"\n",
        "  This tool searches and returns the information from the Stock Information document.\n",
        "  \"\"\"\n",
        "  docs = retriever.invoke(query)\n",
        "\n",
        "  if not docs:\n",
        "    return \"I found no relevant information in the Stock Market Performance 2024 document.\"\n",
        "  results = []\n",
        "  for i,doc in enumerate(docs):\n",
        "    results.append(f\"Document {i+1}:\\n{doc.page_content}\")\n",
        "  return \"\\n\".join(results)\n",
        "\n",
        "tools = [retriever_tool]\n",
        "\n",
        "llm = llm.bind_tools(tools)\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "  messages: Annotated[Sequence[BaseMessage], add_messages]\n",
        "\n",
        "def should_continue(state:AgentState):\n",
        "  \"\"\"\n",
        "  Checks if the last message contains tool calls\n",
        "  \"\"\"\n",
        "  result = state[\"messages\"][-1]\n",
        "  return hasattr(result,'tool_calls') and len(result.tool_calls)>0\n",
        "\n",
        "system_prompt = \"\"\"\n",
        "You are an intelligent AI assistant who answers questions about Stock Market Performance in 2024 based on the PDF document loaded into your knowledge base.\n",
        "Use the retriever tool available to answer questions about the stock market performance data. You can make multiple calls if needed.\n",
        "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
        "Please always cite the specific parts of the documents you use in your answers.\n",
        "\"\"\"\n",
        "\n",
        "tools_dict = {our_tool.name: our_tool for our_tool in tools}\n",
        "\n",
        "def call_llm(state:AgentState):\n",
        "  messages = list(state[\"messages\"])\n",
        "  messages = [SystemMessage(content=system_prompt)] + messages\n",
        "  messages = llm.invoke(messages)\n",
        "  return {'messages':messages}\n",
        "\n",
        "\n",
        "def take_action(state:AgentState) -> AgentState:\n",
        "  \"\"\"Execute tool calls from LLM's response\"\"\"\n",
        "  tool_calls = state[\"messages\"][-1].tool_calls\n",
        "  results = []\n",
        "  for t in tool_calls:\n",
        "    print(f\"Calling tools:{t['name']} with query {t['args'].get('query')}\")\n",
        "    if not t['name'] in tools_dict:\n",
        "      print(f\"Tool {t['name']} not found\")\n",
        "      result = \"Incorrect tool name received\"\n",
        "    else:\n",
        "      result = tools_dict[t['name']].invoke(t['args'].get('query',''))\n",
        "      print(\"Result length\",str(len(result)))\n",
        "\n",
        "    results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
        "\n",
        "  print(\"Tool execution completed\")\n",
        "  return {\"messages\":result }\n",
        "\n",
        "graph = StateGraph(AgentState)\n",
        "graph.add_node(\"call_llm\",call_llm)\n",
        "graph.add_node(\"retriever_agent\",take_action)\n",
        "graph.add_conditional_edges(\"call_llm\",\n",
        "should_continue,\n",
        "{True: \"retriever_agent\", False: END})\n",
        "\n",
        "graph.add_edge(\"retriever_agent\",\"call_llm\")\n",
        "graph.set_entry_point(\"call_llm\")\n",
        "\n",
        "rag_agent = graph.compile()\n",
        "def running_agent():\n",
        "    print(\"\\n=== RAG AGENT===\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"\\nWhat is your question: \")\n",
        "        if user_input.lower() in ['exit', 'quit']:\n",
        "            break\n",
        "\n",
        "        messages = [HumanMessage(content=user_input)] # converts back to a HumanMessage type\n",
        "\n",
        "        result = rag_agent.invoke({\"messages\": messages})\n",
        "\n",
        "        print(\"\\n=== ANSWER ===\")\n",
        "        print(result['messages'][-1].content)\n",
        "\n",
        "\n",
        "running_agent()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPOwHkindJdR",
        "outputId": "13c73462-8476-4c09-c4a0-b99ceb7d7b0a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created ChromaDB vector store\n",
            "\n",
            "=== RAG AGENT===\n",
            "\n",
            "What is your question: which was best performing sector during 2024?\n",
            "Calling tools:retriever_tool with query best performing sector in 2024\n",
            "Result length 4814\n",
            "Tool execution completed\n",
            "\n",
            "=== ANSWER ===\n",
            "Based on the document \"Stock Market Performance in 2024,\" the best-performing sector in 2024 was the technology sector. This is supported by the fact that the \"tech-heavy Nasdaq Composite outpaced the broader market, jumping nearly 29% for the year\" and that a \"key theme was the dominance of mega-cap technology stocks\" (Document 1).\n",
            "\n",
            "What is your question: exit\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgCvmR4jBGp9SogfJvFcre",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}